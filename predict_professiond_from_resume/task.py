# -*- coding: utf-8 -*-
"""practice.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19vZzEMB-fmTEcmrk5Fka98KSgGnuIcfb
"""

import os
os.environ['KAGGLE_USERNAME'] =
os.environ['KAGGLE_KEY'] =
!kaggle datasets download -d gauravduttakiit/resume-dataset

!unzip /content/resume-dataset.zip

import pandas as pd
df1 = pd.read_csv('/content/UpdatedResumeDataSet.csv')

df1.head()

df1['Resume'][0]

"""##Check null values"""

df1.isnull().sum()
df1.isna().sum()

df = df1.fillna('')

df1.isnull().sum()

"""##Preprocessing of text"""

import re
import string
import nltk
# Download necessary NLTK resources
nltk.download('stopwords')
nltk.download('punkt')
nltk.download('punkt_tab')
nltk.download('wordnet')
from nltk.corpus import wordnet
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
STOPWORDS = set(stopwords.words('english'))
from nltk.stem.porter import PorterStemmer
from nltk.stem.wordnet import WordNetLemmatizer

def preprocess_text(txt):
    # Lowercase
    txt = txt.lower()
    # Remove HTML tags (if any)
    txt = re.sub(r"<.*?>", " ", txt)
    # Remove URLs (if any)
    txt = re.sub(r"https?://\S+|www\.\S+", " ", txt)
    # Remove Punctuation
    txt = txt.translate(str.maketrans('', '', string.punctuation))
    # Remove numbers (optional, if you want to keep numbers, you can skip this step)
    txt = re.sub(r'[^A-Za-z\s]', '', txt)
    # Tokenize text
    words = word_tokenize(txt)
    # Remove words less than two letters
    words = [word for word in words if len(word) > 2]
    # Remove stopwords
    words = [word for word in words if word not in STOPWORDS]
    # Lemmatize
    lmt = WordNetLemmatizer()
    words = [lmt.lemmatize(word) for word in words]
    return " ".join(words)


# Sample text (your input text)
text = '''Skills * Programming Languages: Python (pandas, numpy, scipy, scikit-learn, matplotlib), Sql, Java, JavaScript/JQuery. * Machine learning: Regression, SVM, NaÃ¯ve Bayes, KNN, Random Forest, Decision Trees, Boosting techniques, Cluster Analysis, Word Embedding, Sentiment Analysis, Natural Language processing, Dimensionality reduction, Topic Modelling (LDA, NMF), PCA & Neural Nets. * Database Visualizations: Mysql, SqlServer, Cassandra, Hbase, ElasticSearch D3.js, DC.js, Plotly, kibana, matplotlib, ggplot, Tableau. * Others: Regular Expression, HTML, CSS, Angular 6, Logstash, Kafka, Python Flask, Git, Docker, computer vision - Open CV and understanding of Deep learning.Education Details'''

# Preprocess the text
cleaned_text = preprocess_text(text)

# Print the cleaned text
print("Cleaned Text:", cleaned_text)

df1['Resume'] = df1['Resume'].apply(preprocess_text)

df1['Resume'][0]

from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()

le.fit(df1['Category'])
df1['Category'] = le.transform(df1['Category'])

df1.Category.unique()

"""## Vectorization"""

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

from sklearn.feature_extraction.text import TfidfVectorizer
tfidf = TfidfVectorizer(stop_words='english')

tfidf.fit(df1['Resume'])
requiredText  = tfidf.transform(df1['Resume'])

"""## Model Training"""

X = requiredText
Y = df1['Category']

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, stratify=Y, random_state=42)

from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import GaussianNB
from sklearn.multiclass import OneVsRestClassifier
from sklearn.metrics import accuracy_score, classification_report

# Ensure that X_train and X_test are dense if they are sparse
X_train = X_train.toarray() if hasattr(X_train, 'toarray') else X_train
X_test = X_test.toarray() if hasattr(X_test, 'toarray') else X_test

# 1. Train KNeighborsClassifier
knn_model = OneVsRestClassifier(KNeighborsClassifier())
knn_model.fit(X_train, Y_train)

# accuracy score on the train data
X_train_prediction = knn_model.predict(X_train)
training_data_accuracy = accuracy_score(X_train_prediction, Y_train)
print(f'Accuracy on train data : {training_data_accuracy:.4f}')

# accuracy score on the test data
X_test_prediction = knn_model.predict(X_test)
test_data_accuracy = accuracy_score(X_test_prediction, Y_test)
print(f'Accuracy on test data : {test_data_accuracy:.4f}')

print(f"Classification Report:\n{classification_report(Y_test, X_test_prediction)}")

# 2. Train SVC
svc_model = OneVsRestClassifier(SVC())
svc_model.fit(X_train, Y_train)

# accuracy score on the train data
X_train_prediction = svc_model.predict(X_train)
training_data_accuracy = accuracy_score(X_train_prediction, Y_train)
print(f'Accuracy on train data : {training_data_accuracy:.4f}')

# accuracy score on the test data
X_test_prediction = svc_model.predict(X_test)
test_data_accuracy = accuracy_score(X_test_prediction, Y_test)
print(f'Accuracy on test data : {test_data_accuracy:.4f}')

print(f"Classification Report:\n{classification_report(Y_test, X_test_prediction)}")

# 3. Train RandomForestClassifier
rf_model = OneVsRestClassifier(RandomForestClassifier())
rf_model.fit(X_train, Y_train)

# accuracy score on the train data
X_train_prediction = rf_model.predict(X_train)
training_data_accuracy = accuracy_score(X_train_prediction, Y_train)
print(f'Accuracy on train data : {training_data_accuracy:.4f}')

# accuracy score on the test data
X_test_prediction = rf_model.predict(X_test)
test_data_accuracy = accuracy_score(X_test_prediction, Y_test)
print(f'Accuracy on test data : {test_data_accuracy:.4f}')

print(f"Classification Report:\n{classification_report(Y_test, X_test_prediction)}")

import pickle
pickle.dump(tfidf,open('tfidf.pkl','wb')) # vectorizer
pickle.dump(svc_model, open('clf.pkl', 'wb')) # model
pickle.dump(le, open("encoder.pkl",'wb')) # labelEncoder

import pickle

tfidf = pickle.load(open('tfidf.pkl', 'rb'))
svc_model = pickle.load(open('clf.pkl', 'rb'))
le = pickle.load(open('encoder.pkl', 'rb'))

# Function to predict the category of a resume
def pred(input_resume):
    # Preprocess the input text (e.g., cleaning, etc.)
    cleaned_text = preprocess_text(input_resume)

    # Vectorize the cleaned text using the same TF-IDF vectorizer used during training
    vectorized_text = tfidf.transform([cleaned_text])

    # Convert sparse matrix to dense
    vectorized_text = vectorized_text.toarray()

    # Prediction
    predicted_category = svc_model.predict(vectorized_text)

    # get name of predicted category
    predicted_category_name = le.inverse_transform(predicted_category)

    return predicted_category_name[0]

myresume = """I am a data scientist specializing in machine
learning, deep learning, and computer vision. With
a strong background in mathematics, statistics,
and programming, I am passionate about
uncovering hidden patterns and insights in data.
I have extensive experience in developing
predictive models, implementing deep learning
algorithms, and designing computer vision
systems. My technical skills include proficiency in
Python, Sklearn, TensorFlow, and PyTorch.
What sets me apart is my ability to effectively
communicate complex concepts to diverse
audiences. I excel in translating technical insights
into actionable recommendations that drive
informed decision-making.
If you're looking for a dedicated and versatile data
scientist to collaborate on impactful projects, I am
eager to contribute my expertise. Let's harness the
power of data together to unlock new possibilities
and shape a better future.
Contact & Sources
Email: 611noorsaeed@gmail.com
Phone: 03442826192
Github: https://github.com/611noorsaeed
Linkdin: https://www.linkedin.com/in/noor-saeed654a23263/
Blogs: https://medium.com/@611noorsaeed
Youtube: Artificial Intelligence
ABOUT ME
WORK EXPERIENCE
SKILLES
NOOR SAEED
LANGUAGES
English
Urdu
Hindi
I am a versatile data scientist with expertise in a wide
range of projects, including machine learning,
recommendation systems, deep learning, and computer
vision. Throughout my career, I have successfully
developed and deployed various machine learning models
to solve complex problems and drive data-driven
decision-making
Machine Learnine
Deep Learning
Computer Vision
Recommendation Systems
Data Visualization
Programming Languages (Python, SQL)
Data Preprocessing and Feature Engineering
Model Evaluation and Deployment
Statistical Analysis
Communication and Collaboration
"""

pred(myresume)