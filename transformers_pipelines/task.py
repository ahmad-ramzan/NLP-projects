# -*- coding: utf-8 -*-
"""practice.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19vZzEMB-fmTEcmrk5Fka98KSgGnuIcfb
"""

!pip install transformers torch

from transformers import AutoTokenizer, AutoModelForSequenceClassification

# Downloads and caches both model and tokenizer
AutoModelForSequenceClassification.from_pretrained(
    'distilbert/distilbert-base-uncased-finetuned-sst-2-english'
)
AutoTokenizer.from_pretrained(
    'distilbert/distilbert-base-uncased-finetuned-sst-2-english'
)

# Downloads and caches both model and tokenizer
AutoModelForSequenceClassification.from_pretrained(
    'gpt2'
)
AutoTokenizer.from_pretrained(
    'gpt2'
)

# Downloads and caches both model and tokenizer
AutoModelForSequenceClassification.from_pretrained(
    'facebook/bart-large-cnn'
)
AutoTokenizer.from_pretrained(
    'facebook/bart-large-cnn'
)

# Downloads and caches both model and tokenizer
AutoModelForSequenceClassification.from_pretrained(
    'dbmdz/bert-large-cased-finetuned-conll03-english'
)
AutoTokenizer.from_pretrained(
    'dbmdz/bert-large-cased-finetuned-conll03-english'
)

from transformers import pipeline

# 1Ô∏è‚É£ Sentiment Analysis (English)
sentiment_pipeline = pipeline(
    'sentiment-analysis',
    model='distilbert/distilbert-base-uncased-finetuned-sst-2-english'
)

text1 = "I love this product! It's really useful and well-designed."
sentiment_result = sentiment_pipeline(text1)
print("üîç Sentiment Analysis:", sentiment_result)

# 2Ô∏è‚É£ Text Generation
generation_pipeline = pipeline(
    'text-generation',
    model='gpt2'
)

prompt = "Artificial Intelligence will change the future because"
generation_result = generation_pipeline(prompt, max_length=50, num_return_sequences=1)
print("\nüìù Text Generation:", generation_result[0]['generated_text'])

# 3Ô∏è‚É£ Translation (French to English)
translation_pipeline = pipeline(
    'translation_fr_to_en',
    model="Helsinki-NLP/opus-mt-fr-en"
)

french_text = "Je suis tr√®s heureux de vous rencontrer."
translation_result = translation_pipeline(french_text)
print("\nüåê Translation (FR ‚û° EN):", translation_result[0]['translation_text'])

# 4Ô∏è‚É£ Summarization
summarization_pipeline = pipeline(
    'summarization',
    model='facebook/bart-large-cnn'
)

long_text = """
NASA's Artemis program aims to return humans to the Moon by the mid-2020s, as a stepping stone for further exploration
of Mars and beyond. The program includes new spacecraft, landers, and plans to establish a sustainable human presence
on the Moon for the first time.
"""
summary_result = summarization_pipeline(long_text, max_length=50, min_length=20, do_sample=False)
print("\nüìö Summarization:", summary_result[0]['summary_text'])

# 5Ô∏è‚É£ Named Entity Recognition (NER)
NER_pipeline = pipeline(
    "ner",
    model="dbmdz/bert-large-cased-finetuned-conll03-english",
    grouped_entities=True
)

ner_text = "Barack Obama was born in Hawaii and served as President of the United States."
ner_result = NER_pipeline(ner_text)
print("\nüß† Named Entity Recognition:", ner_result)